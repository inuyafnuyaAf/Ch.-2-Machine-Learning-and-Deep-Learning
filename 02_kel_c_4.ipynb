{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Avr_BuLrV23M"
      },
      "source": [
        "# Assignment Chapter 2 - DEEP LEARNING [Case #4]\n",
        "Startup Campus, Indonesia - `Artificial Intelligence (AI)` (Batch 7)\n",
        "* Task: **CLASSIFICATION**\n",
        "* DL Framework: **PyTorch**\n",
        "* Dataset: Credit Card Fraud 2023\n",
        "* Libraries: Pandas/cuDF, Scikit-learn/cuML, Numpy/cuPy\n",
        "* Objective: Classify credit fraud transactions using Multilayer Perceptron\n",
        "\n",
        "`PERSYARATAN` Semua modul (termasuk versi yang sesuai) sudah di-install dengan benar.\n",
        "<br>`CARA PENGERJAAN` Lengkapi baris kode yang ditandai dengan **#TODO**.\n",
        "<br>`TARGET PORTFOLIO` Peserta mampu mengklasifikasi transaksi fraud menggunakan *Multilayer Perceptron*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5YZC_D_ZCEy"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvStCFqxZlrS",
        "outputId": "363c318c-0fb3-4c4f-f03e-e52adc7531e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'rapidsai-csp-utils'...\n",
            "remote: Enumerating objects: 520, done.\u001b[K\n",
            "remote: Counting objects: 100% (251/251), done.\u001b[K\n",
            "remote: Compressing objects: 100% (157/157), done.\u001b[K\n",
            "remote: Total 520 (delta 165), reused 129 (delta 94), pack-reused 269 (from 1)\u001b[K\n",
            "Receiving objects: 100% (520/520), 166.85 KiB | 889.00 KiB/s, done.\n",
            "Resolving deltas: 100% (267/267), done.\n",
            "Collecting pynvml\n",
            "  Downloading pynvml-11.5.3-py3-none-any.whl.metadata (8.8 kB)\n",
            "Downloading pynvml-11.5.3-py3-none-any.whl (53 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.1/53.1 kB 2.7 MB/s eta 0:00:00\n",
            "Installing collected packages: pynvml\n",
            "Successfully installed pynvml-11.5.3\n",
            "Installing RAPIDS remaining 24.4.* libraries\n",
            "Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\n",
            "Collecting cudf-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/cudf-cu12/cudf_cu12-24.4.1-cp310-cp310-manylinux_2_28_x86_64.whl (473.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 473.3/473.3 MB 1.3 MB/s eta 0:00:00\n",
            "Collecting cuml-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/cuml-cu12/cuml_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1200.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 GB 553.7 kB/s eta 0:00:00\n",
            "Collecting cugraph-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/cugraph-cu12/cugraph_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1429.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 GB ? eta 0:00:00\n",
            "Collecting cuspatial-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/cuspatial-cu12/cuspatial_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 137.8/137.8 MB 7.3 MB/s eta 0:00:00\n",
            "Collecting cuproj-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/cuproj-cu12/cuproj_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (920 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 920.9/920.9 kB 55.6 MB/s eta 0:00:00\n",
            "Collecting cuxfilter-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/cuxfilter-cu12/cuxfilter_cu12-24.4.1-py3-none-any.whl (83 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 83.5/83.5 kB 7.6 MB/s eta 0:00:00\n",
            "Collecting cucim-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/cucim-cu12/cucim_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.8/5.8 MB 100.7 MB/s eta 0:00:00\n",
            "Collecting pylibraft-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/pylibraft-cu12/pylibraft_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (823.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 823.0/823.0 MB 1.1 MB/s eta 0:00:00\n",
            "Collecting raft-dask-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/raft-dask-cu12/raft_dask_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (170.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 170.1/170.1 MB 7.0 MB/s eta 0:00:00\n",
            "Collecting nx-cugraph-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/nx-cugraph-cu12/nx_cugraph_cu12-24.4.0-py3-none-any.whl (125 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 125.7/125.7 kB 12.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (3.10.9)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (5.5.0)\n",
            "Requirement already satisfied: cuda-python<13.0a0,>=12.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (12.2.1)\n",
            "Requirement already satisfied: cupy-cuda12x>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (12.2.0)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (2024.6.1)\n",
            "Requirement already satisfied: numba>=0.57 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (0.60.0)\n",
            "Requirement already satisfied: numpy<2.0a0,>=1.23 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (1.26.4)\n",
            "Requirement already satisfied: nvtx>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (0.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (24.1)\n",
            "Collecting pandas<2.2.2dev0,>=2.0 (from cudf-cu12==24.4.*)\n",
            "  Downloading pandas-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (3.20.3)\n",
            "Requirement already satisfied: pynvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (0.3.0)\n",
            "Collecting pyarrow<15.0.0a0,>=14.0.1 (from cudf-cu12==24.4.*)\n",
            "  Downloading pyarrow-14.0.2-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (13.9.2)\n",
            "Collecting rmm-cu12==24.4.* (from cudf-cu12==24.4.*)\n",
            "  Downloading https://pypi.nvidia.com/rmm-cu12/rmm_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 74.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (4.12.2)\n",
            "Collecting dask-cuda==24.4.* (from cuml-cu12==24.4.*)\n",
            "  Downloading dask_cuda-24.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting dask-cudf-cu12==24.4.* (from cuml-cu12==24.4.*)\n",
            "  Downloading https://pypi.nvidia.com/dask-cudf-cu12/dask_cudf_cu12-24.4.1-py3-none-any.whl (48 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.9/48.9 kB 4.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from cuml-cu12==24.4.*) (1.4.2)\n",
            "Collecting rapids-dask-dependency==24.4.* (from cuml-cu12==24.4.*)\n",
            "  Downloading https://pypi.nvidia.com/rapids-dask-dependency/rapids_dask_dependency-24.4.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from cuml-cu12==24.4.*) (1.13.1)\n",
            "Collecting treelite==4.1.2 (from cuml-cu12==24.4.*)\n",
            "  Downloading treelite-4.1.2-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting pylibcugraph-cu12==24.4.* (from cugraph-cu12==24.4.*)\n",
            "  Downloading https://pypi.nvidia.com/pylibcugraph-cu12/pylibcugraph_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1430.2 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 GB 1.4 MB/s eta 0:00:00\n",
            "Collecting ucx-py-cu12==0.37.* (from cugraph-cu12==24.4.*)\n",
            "  Downloading https://pypi.nvidia.com/ucx-py-cu12/ucx_py_cu12-0.37.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.7/7.7 MB 96.7 MB/s eta 0:00:00\n",
            "Requirement already satisfied: geopandas>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from cuspatial-cu12==24.4.*) (1.0.1)\n",
            "Requirement already satisfied: bokeh>=3.1 in /usr/local/lib/python3.10/dist-packages (from cuxfilter-cu12==24.4.*) (3.4.3)\n",
            "Collecting datashader>=0.15 (from cuxfilter-cu12==24.4.*)\n",
            "  Downloading datashader-0.16.3-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: holoviews>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from cuxfilter-cu12==24.4.*) (1.19.1)\n",
            "Collecting jupyter-server-proxy (from cuxfilter-cu12==24.4.*)\n",
            "  Downloading jupyter_server_proxy-4.4.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: panel>=1.0 in /usr/local/lib/python3.10/dist-packages (from cuxfilter-cu12==24.4.*) (1.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from cucim-cu12==24.4.*) (8.1.7)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from cucim-cu12==24.4.*) (0.4)\n",
            "Collecting scikit-image<0.23.0a0,>=0.19.0 (from cucim-cu12==24.4.*)\n",
            "  Downloading scikit_image-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from nx-cugraph-cu12==24.4.*) (3.3)\n",
            "Collecting pynvml<11.5,>=11.0.0 (from dask-cuda==24.4.*->cuml-cu12==24.4.*)\n",
            "  Downloading pynvml-11.4.1-py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: zict>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from dask-cuda==24.4.*->cuml-cu12==24.4.*) (3.0.0)\n",
            "Collecting dask==2024.1.1 (from rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*)\n",
            "  Downloading dask-2024.1.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting distributed==2024.1.1 (from rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*)\n",
            "  Downloading distributed-2024.1.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting dask-expr==0.4.0 (from rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*)\n",
            "  Downloading dask_expr-0.4.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (2.2.1)\n",
            "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (6.0.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (8.4.0)\n",
            "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (3.1.4)\n",
            "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (1.0.0)\n",
            "Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (1.0.8)\n",
            "Requirement already satisfied: psutil>=5.7.2 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (5.9.5)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (3.0.0)\n",
            "Requirement already satisfied: tornado>=6.0.4 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (6.3.3)\n",
            "Requirement already satisfied: urllib3>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (2.2.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.13.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (4.0.3)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->cuxfilter-cu12==24.4.*) (1.3.0)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->cuxfilter-cu12==24.4.*) (10.4.0)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->cuxfilter-cu12==24.4.*) (2024.9.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from cuda-python<13.0a0,>=12.0->cudf-cu12==24.4.*) (3.0.11)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda12x>=12.0.0->cudf-cu12==24.4.*) (0.8.2)\n",
            "Requirement already satisfied: colorcet in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.4.*) (3.1.0)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.4.*) (1.0.0)\n",
            "Requirement already satisfied: param in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.4.*) (2.1.1)\n",
            "Collecting pyct (from datashader>=0.15->cuxfilter-cu12==24.4.*)\n",
            "  Downloading pyct-0.5.0-py2.py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.4.*) (2.32.3)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.4.*) (2024.9.0)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from geopandas>=0.11.0->cuspatial-cu12==24.4.*) (0.10.0)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from geopandas>=0.11.0->cuspatial-cu12==24.4.*) (3.7.0)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from geopandas>=0.11.0->cuspatial-cu12==24.4.*) (2.0.6)\n",
            "Requirement already satisfied: pyviz-comms>=2.1 in /usr/local/lib/python3.10/dist-packages (from holoviews>=1.16.0->cuxfilter-cu12==24.4.*) (3.0.3)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.57->cudf-cu12==24.4.*) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.2dev0,>=2.0->cudf-cu12==24.4.*) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.2dev0,>=2.0->cudf-cu12==24.4.*) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.2dev0,>=2.0->cudf-cu12==24.4.*) (2024.2)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.4.*) (3.7)\n",
            "Requirement already satisfied: markdown-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.4.*) (3.0.0)\n",
            "Requirement already satisfied: linkify-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.4.*) (2.0.3)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.4.*) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.4.*) (4.66.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.4.*) (6.1.0)\n",
            "Requirement already satisfied: imageio>=2.27 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.23.0a0,>=0.19.0->cucim-cu12==24.4.*) (2.35.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.23.0a0,>=0.19.0->cucim-cu12==24.4.*) (2024.9.20)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp) (3.10)\n",
            "Requirement already satisfied: jupyter-server>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.24.0)\n",
            "Collecting simpervisor>=1.0.0 (from jupyter-server-proxy->cuxfilter-cu12==24.4.*)\n",
            "  Downloading simpervisor-1.0.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server-proxy->cuxfilter-cu12==24.4.*) (5.7.1)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->cudf-cu12==24.4.*) (2.18.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.10.3->distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (2.1.5)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (3.7.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (23.1.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (6.1.12)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (5.7.2)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (6.5.4)\n",
            "Requirement already satisfied: nbformat>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (5.10.4)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.21.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (24.0.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.18.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.8.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py->panel>=1.0->cuxfilter-cu12==24.4.*) (0.1.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pyogrio>=0.7.2->geopandas>=0.11.0->cuspatial-cu12==24.4.*) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<2.2.2dev0,>=2.0->cudf-cu12==24.4.*) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->panel>=1.0->cuxfilter-cu12==24.4.*) (0.5.1)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py->panel>=1.0->cuxfilter-cu12==24.4.*) (1.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->datashader>=0.15->cuxfilter-cu12==24.4.*) (3.3.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.2.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (3.20.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (4.3.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (4.12.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.3.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (4.23.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (21.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.20.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (2.22)\n",
            "Downloading dask_cuda-24.4.0-py3-none-any.whl (126 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 126.6/126.6 kB 6.6 MB/s eta 0:00:00\n",
            "Downloading treelite-4.1.2-py3-none-manylinux2014_x86_64.whl (810 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 810.9/810.9 kB 29.0 MB/s eta 0:00:00\n",
            "Downloading dask-2024.1.1-py3-none-any.whl (1.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 53.9 MB/s eta 0:00:00\n",
            "Downloading dask_expr-0.4.0-py3-none-any.whl (161 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 161.7/161.7 kB 14.4 MB/s eta 0:00:00\n",
            "Downloading distributed-2024.1.1-py3-none-any.whl (1.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 53.6 MB/s eta 0:00:00\n",
            "Downloading datashader-0.16.3-py2.py3-none-any.whl (18.3 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.3/18.3 MB 88.0 MB/s eta 0:00:00\n",
            "Downloading pandas-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.0/13.0 MB 97.8 MB/s eta 0:00:00\n",
            "Downloading pyarrow-14.0.2-cp310-cp310-manylinux_2_28_x86_64.whl (38.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 38.0/38.0 MB 17.0 MB/s eta 0:00:00\n",
            "Downloading scikit_image-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.7/14.7 MB 96.8 MB/s eta 0:00:00\n",
            "Downloading jupyter_server_proxy-4.4.0-py3-none-any.whl (37 kB)\n",
            "Downloading pynvml-11.4.1-py3-none-any.whl (46 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 47.0/47.0 kB 4.3 MB/s eta 0:00:00\n",
            "Downloading simpervisor-1.0.0-py3-none-any.whl (8.3 kB)\n",
            "Downloading pyct-0.5.0-py2.py3-none-any.whl (15 kB)\n",
            "Installing collected packages: simpervisor, pynvml, pyct, pyarrow, ucx-py-cu12, treelite, scikit-image, rmm-cu12, pandas, dask, pylibraft-cu12, distributed, dask-expr, cuproj-cu12, cudf-cu12, cucim-cu12, rapids-dask-dependency, pylibcugraph-cu12, datashader, cuspatial-cu12, nx-cugraph-cu12, dask-cudf-cu12, dask-cuda, raft-dask-cu12, cuml-cu12, cugraph-cu12, jupyter-server-proxy, cuxfilter-cu12\n",
            "  Attempting uninstall: pynvml\n",
            "    Found existing installation: pynvml 11.5.3\n",
            "    Uninstalling pynvml-11.5.3:\n",
            "      Successfully uninstalled pynvml-11.5.3\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 16.1.0\n",
            "    Uninstalling pyarrow-16.1.0:\n",
            "      Successfully uninstalled pyarrow-16.1.0\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.24.0\n",
            "    Uninstalling scikit-image-0.24.0:\n",
            "      Successfully uninstalled scikit-image-0.24.0\n",
            "  Attempting uninstall: rmm-cu12\n",
            "    Found existing installation: rmm-cu12 24.6.0\n",
            "    Uninstalling rmm-cu12-24.6.0:\n",
            "      Successfully uninstalled rmm-cu12-24.6.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2024.8.0\n",
            "    Uninstalling dask-2024.8.0:\n",
            "      Successfully uninstalled dask-2024.8.0\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 2024.8.0\n",
            "    Uninstalling distributed-2024.8.0:\n",
            "      Successfully uninstalled distributed-2024.8.0\n",
            "  Attempting uninstall: cudf-cu12\n",
            "    Found existing installation: cudf-cu12 24.6.1\n",
            "    Uninstalling cudf-cu12-24.6.1:\n",
            "      Successfully uninstalled cudf-cu12-24.6.1\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.1 which is incompatible.\n",
            "Successfully installed cucim-cu12-24.4.0 cudf-cu12-24.4.1 cugraph-cu12-24.4.0 cuml-cu12-24.4.0 cuproj-cu12-24.4.0 cuspatial-cu12-24.4.0 cuxfilter-cu12-24.4.1 dask-2024.1.1 dask-cuda-24.4.0 dask-cudf-cu12-24.4.1 dask-expr-0.4.0 datashader-0.16.3 distributed-2024.1.1 jupyter-server-proxy-4.4.0 nx-cugraph-cu12-24.4.0 pandas-2.2.1 pyarrow-14.0.2 pyct-0.5.0 pylibcugraph-cu12-24.4.0 pylibraft-cu12-24.4.0 pynvml-11.4.1 raft-dask-cu12-24.4.0 rapids-dask-dependency-24.4.1 rmm-cu12-24.4.0 scikit-image-0.22.0 simpervisor-1.0.0 treelite-4.1.2 ucx-py-cu12-0.37.0\n",
            "\n",
            "        ***********************************************************************\n",
            "        The pip install of RAPIDS is complete.\n",
            "        \n",
            "        Please do not run any further installation from the conda based installation methods, as they may cause issues!\n",
            "        \n",
            "        Please ensure that you're pulling from the git repo to remain updated with the latest working install scripts.\n",
            "\n",
            "        Troubleshooting:\n",
            "            - If there is an installation failure, please check back on RAPIDSAI owned templates/notebooks to see how to update your personal files. \n",
            "            - If an installation failure persists when using the latest script, please make an issue on https://github.com/rapidsai-community/rapidsai-csp-utils\n",
            "        ***********************************************************************\n",
            "        \n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
        "!python rapidsai-csp-utils/colab/pip-install.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "WkP5jZSIZCE7"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "861X-2gEEnY3"
      },
      "source": [
        "<font color=\"red\">**- - - - MOHON DIPERHATIKAN - - - -**</font>\n",
        "<br>**Aktifkan GPU sekarang.** Di Google Colab, klik **Runtime > Change Runtime Type**, lalu pilih **T4 GPU**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSvMfJL1ZCE_"
      },
      "source": [
        "### Dataset Loading (CPU vs. GPU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gnAKcO7kUPA"
      },
      "outputs": [],
      "source": [
        "from pandas import read_csv as read_by_CPU\n",
        "from cudf import read_csv as read_by_GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ojn_qv6ucAcO"
      },
      "outputs": [],
      "source": [
        "# unzip the file\n",
        "shutil.unpack_archive('data_case_04.zip', '/content/sample_data/', 'zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOQKgmXYZCFB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3630e971-0709-448a-c1c6-c448b2c77019"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5.33 s, sys: 0 ns, total: 5.33 s\n",
            "Wall time: 5.24 s\n"
          ]
        }
      ],
      "source": [
        "# TODO: Impor dataset dengan Pandas, gunakan fungsi \"read_by_CPU\"\n",
        "%time data_cpu = read_by_CPU('/content/sample_data/creditcard_2023.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8kOLF4ncWe_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cda37b8-5369-4f31-bce5-0f6e54cd0c74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 311 ms, sys: 0 ns, total: 311 ms\n",
            "Wall time: 340 ms\n"
          ]
        }
      ],
      "source": [
        "# Impor dataset dengan cuDF (Pandas di GPU)\n",
        "%time data_gpu = read_by_GPU('/content/sample_data/creditcard_2023.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paQFb9zLZCFC"
      },
      "outputs": [],
      "source": [
        "# TODO: Hilangkan kolom ID\n",
        "data_gpu = data_gpu.drop(columns=['id'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2FBAhocj1IR"
      },
      "source": [
        "### Standardization (CPU vs. GPU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cBn8jNskGDS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8c8eb68-cd3d-4541-a32a-9ba854369bf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.Tensor size changed, may indicate binary incompatibility. Expected 64 from C header, got 80 from PyObject\n",
            "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.NativeFile size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n",
            "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.BufferedInputStream size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n",
            "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.BufferedOutputStream size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n",
            "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.CompressedInputStream size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n",
            "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.CompressedOutputStream size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler as StandardScalerCPU\n",
        "from cuml.preprocessing import StandardScaler as StandardScalerGPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcpTE3osjZKc"
      },
      "outputs": [],
      "source": [
        "ScalerCPU = StandardScalerCPU()\n",
        "ScalerGPU = StandardScalerGPU()\n",
        "\n",
        "arbitrary_features = [\"V\"+str(i+1) for i in range(27)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qkT_zVUZCFF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "111adae8-044f-451b-8bd0-2a1efc5b9451"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 194 ms, sys: 101 ms, total: 295 ms\n",
            "Wall time: 291 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "data_cpu[arbitrary_features] = ScalerCPU.fit_transform(data_cpu[arbitrary_features].values)\n",
        "data_cpu[\"Amount\"] = ScalerCPU.fit_transform(data_cpu[\"Amount\"].values.reshape(-1, 1)).squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcD5PCr7ePCZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "095ac6ee-7377-4bf6-82a7-9bcbc6c38a09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 16.5 s, sys: 5.58 ms, total: 16.5 s\n",
            "Wall time: 16.6 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "data_gpu[arbitrary_features] = ScalerGPU.fit_transform(data_gpu[arbitrary_features].values)\n",
        "data_gpu[\"Amount\"] = ScalerGPU.fit_transform(data_gpu[\"Amount\"].values.reshape(-1, 1)).squeeze()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wp7MqaUrZCFJ"
      },
      "source": [
        "### Train/Test Split (CPU vs. GPU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXlDibQ_jps4"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split as splitCPU\n",
        "from cuml.preprocessing import train_test_split as splitGPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0kl7RQQZCFH"
      },
      "outputs": [],
      "source": [
        "# TODO: Tentukan X (features) dan Y (target), gunakan \"data_gpu\"\n",
        "X = data_gpu.iloc[:,:-1]\n",
        "Y = data_gpu['Class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Re8mIqeKZCFK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a90b8973-aa05-4d5e-b4dc-8cd222711e44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape:  (454904, 29)\n",
            "x_test shape:  (113726, 29)\n",
            "CPU times: user 60.6 ms, sys: 0 ns, total: 60.6 ms\n",
            "Wall time: 121 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# TODO: Pecah dataset dengan komposisi 80% train set dan 20% test set, dengan fungsi \"splitCPU\"\n",
        "test_size = 0.2\n",
        "random_state = 42\n",
        "x_train, x_test, y_train, y_test = splitCPU(X, Y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "print(\"x_train shape: \", x_train.shape)\n",
        "print(\"x_test shape: \", x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJF3WiFXiPeX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f457ea87-d96b-4ed0-acab-5d83a805e8dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape:  (454904, 29)\n",
            "x_test shape:  (113726, 29)\n",
            "CPU times: user 740 ms, sys: 0 ns, total: 740 ms\n",
            "Wall time: 826 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# TODO: Lakukan hal yang sama untuk data spliting, tetapi dengan fungsi \"splitGPU\"\n",
        "test_size = 0.2\n",
        "random_state = 42\n",
        "x_train, x_test, y_train, y_test = splitGPU(X, Y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "print(\"x_train shape: \", x_train.shape)\n",
        "print(\"x_test shape: \", x_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZcVl4wgZCFO"
      },
      "source": [
        "### Convert the dataset into Tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciQHEDCcu074"
      },
      "outputs": [],
      "source": [
        "import cupy # Numpy for GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYPaM_UMZCFP"
      },
      "outputs": [],
      "source": [
        "# TODO: Aktifkan GPU (CUDA) sebagai device untuk training\n",
        "device = torch.device('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84408FY1ZCFQ"
      },
      "outputs": [],
      "source": [
        "x_train_tensor = torch.from_numpy(cupy.asnumpy(x_train.to_cupy())).to(device)\n",
        "y_train_tensor = torch.from_numpy(cupy.asnumpy(y_train)).to(device)\n",
        "\n",
        "x_test_tensor = torch.from_numpy(cupy.asnumpy(x_test.to_cupy())).to(device)\n",
        "y_test_tensor = torch.from_numpy(cupy.asnumpy(y_test)).to(device)\n",
        "\n",
        "Train_tensor = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "Test_tensor = TensorDataset(x_test_tensor, y_test_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9spIXPHZCFR"
      },
      "source": [
        "### Batching the Dataset with PyTorch DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ld5CPEnPZCFR"
      },
      "outputs": [],
      "source": [
        "# TODO: Tentukan nilai batch\n",
        "batch_size = 64\n",
        "\n",
        "Train_dataset = DataLoader(Train_tensor, batch_size=batch_size, shuffle=True)\n",
        "Test_dataset = DataLoader(Test_tensor, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwpmEpwbZCFS"
      },
      "source": [
        "### Model Blueprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqDbyYGPZCFT"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, input_dim, num_neurons):\n",
        "        super(FeedForward, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.num_neurons = num_neurons\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, self.num_neurons),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "    def to(self, device):\n",
        "        self.net.to(device)\n",
        "        return self\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, in_features, num_layers, num_neurons):\n",
        "        super(Net, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.num_layers = num_layers\n",
        "        self.num_neurons = num_neurons\n",
        "\n",
        "        self.fc1 = nn.Linear(self.in_features, self.num_neurons)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.blocks = [FeedForward(self.num_neurons, self.num_neurons).to(device) \\\n",
        "                       for _ in range(self.num_layers)]\n",
        "        self.output_layer = nn.Linear(self.num_neurons, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.relu(self.fc1(x))\n",
        "\n",
        "        for block in self.blocks:\n",
        "            output = block(output)\n",
        "        output = self.sigmoid(self.output_layer(output))\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31B0wSqcZCFT"
      },
      "source": [
        "### Model Hyperparameters and Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fr2hoJxGZCFU"
      },
      "outputs": [],
      "source": [
        "# [ PERTANYAAN ]\n",
        "# Apa perbedaan hyperparameters dan parameters?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cplhcw09ZCFU"
      },
      "source": [
        "[ Parameters adalah nilai yang dioptimalkan selama pelatihan, sedangkan hyperparameters adalah nilai yang ditentukan sebelum pelatihan dan berdampak pada cara model belajar serta kinerjanya, seperti epochs, num_layers, num_neurons, dan learning_rate ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jCK25QXZCFV"
      },
      "outputs": [],
      "source": [
        "# TODO: Tentukan hyperparameters\n",
        "epochs = 50\n",
        "num_layers = 4\n",
        "num_neurons = 128\n",
        "learning_rate = 0.0001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_6bIeQ_ZCFV"
      },
      "outputs": [],
      "source": [
        "# TODO: Tentukan besaran input untuk model\n",
        "num_inputs = 29\n",
        "\n",
        "model = Net(in_features=num_inputs, num_layers=num_layers, num_neurons=num_neurons)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6ldLoneZCFW"
      },
      "outputs": [],
      "source": [
        "# Set the optimizer and loss function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Z-DVlMqZCFW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eecdca39-c3e8-4265-b7a5-ab5c00689a7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 3,969\n",
            "Number of trainable parameters: 3,969\n"
          ]
        }
      ],
      "source": [
        "# Check the number of parameters\n",
        "print(\"Number of parameters: {:,}\".format(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
        "print(\"Number of trainable parameters: {:,}\".format(sum(p.numel() for p in model.parameters() if p.requires_grad)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iDhRA5rZCFX"
      },
      "outputs": [],
      "source": [
        "# [ PERTANYAAN ]\n",
        "# Mengapa total \"trainable parameters\" sama dengan total keseluruhan parameter?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onibsgQ3ZCFX"
      },
      "source": [
        "[ Dalam arsitektur neural network, tidak ada parameter yang ditandai sebagai non-trainable. Semua bobot dan bias dalam model ini ditujukan untuk dilatih selama proses pembelajaran.\n",
        "Oleh karena itu, semua parameter yang ada di dalam model (3,969) juga merupakan parameter yang dapat dilatih, sehingga jumlah \"Number of parameters\" sama dengan \"Number of trainable parameters\" ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU8zMjOQZCFX"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqITlQXCZCFX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "334c1db1-aba0-40e6-e34b-ba20dcf6288b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training ...\n",
            "  - Epoch: 0 \tTraining_loss: 0.000321\n",
            "  - Epoch: 10 \tTraining_loss: 0.000173\n",
            "  - Epoch: 20 \tTraining_loss: 0.000107\n",
            "  - Epoch: 30 \tTraining_loss: 0.000075\n",
            "  - Epoch: 40 \tTraining_loss: 0.000057\n"
          ]
        }
      ],
      "source": [
        "print(\"Start training ...\")\n",
        "for epoch in range(epochs):\n",
        "    train_loss = 0.0\n",
        "    model.train()\n",
        "\n",
        "    for data, label in Train_dataset:\n",
        "        data = data.to(device)\n",
        "        label = label.squeeze()\n",
        "        label = label.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(data.float())\n",
        "\n",
        "        loss = criterion(output.squeeze(), label.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss = train_loss / len(Train_dataset.dataset)\n",
        "    if(epoch % 10 == 0):\n",
        "        print('  - Epoch: {} \\tTraining_loss: {:.6f}'.format(epoch, train_loss))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CL3lJaDVZCFY"
      },
      "source": [
        "### Model ACCURACY should reach >= 95%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReIlo4acxGCR"
      },
      "outputs": [],
      "source": [
        "# TODO: Jika akurasi masih dibawah 95%, silakan lakukan fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPQKtHsBZCFZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32cd61b7-9605-4994-89a3-32883b3f980c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 99.93%\n"
          ]
        }
      ],
      "source": [
        "correct_preds = 0\n",
        "total_samples = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, labels in Test_dataset:\n",
        "        labels = labels.squeeze()\n",
        "        output = model.forward(data.float())\n",
        "        output = output.squeeze(1)\n",
        "\n",
        "        predictions = (output >= 0.5).float()\n",
        "        correct_preds += (predictions == labels).sum().item()\n",
        "        total_samples += labels.numel()\n",
        "\n",
        "accuracy = correct_preds / total_samples\n",
        "print(\"Model accuracy: {:.2f}%\".format(accuracy*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd8Td1YsV23w"
      },
      "source": [
        "### Scoring\n",
        "Total `#TODO` = 12\n",
        "<br>Checklist:\n",
        "\n",
        "- [ ] Impor dataset dengan Pandas, gunakan fungsi \"read_by_CPU\"\n",
        "- [ ] Hilangkan kolom ID\n",
        "- [ ] Tentukan X (features) dan Y (target), gunakan \"data_gpu\"\n",
        "- [ ] Pecah dataset dengan komposisi 80% train set dan 20% test set, dengan fungsi \"splitCPU\"\n",
        "- [ ] Lakukan hal yang sama untuk data spliting, tetapi dengan fungsi \"splitGPU\"\n",
        "- [ ] Aktifkan GPU (CUDA) sebagai device untuk training\n",
        "- [ ] Tentukan nilai batch\n",
        "- [ ] PERTANYAAN: Apa perbedaan hyperparameters dan parameters?\n",
        "- [ ] Tentukan hyperparameters\n",
        "- [ ] Tentukan besaran input untuk model\n",
        "- [ ] PERTANYAAN: Mengapa total \"trainable parameters\" sama dengan total keseluruhan parameter?\n",
        "- [ ] Jika akurasi masih dibawah 95%, silakan lakukan fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nu54eCVrV23w"
      },
      "source": [
        "### Additional readings\n",
        "- N/A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lozabSPV23w"
      },
      "source": [
        "### Copyright © 2024 Startup Campus, Indonesia\n",
        "* Prepared by **Nicholas Dominic, M.Kom.** [(profile)](https://linkedin.com/in/nicholas-dominic)\n",
        "* You may **NOT** use this file except there is written permission from PT. Kampus Merdeka Belajar (Startup Campus).\n",
        "* Please address your questions to mentors."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 3752264,
          "sourceId": 6492730,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30626,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}